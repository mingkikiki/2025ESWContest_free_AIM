# ì „ì´í•™ìŠµ ê¸°ë°˜ ì—°ë ¹ ë¶„ë¥˜ ëª¨ë¸ - ì˜¤ë¥˜ ìˆ˜ì • ë° ìµœì¢… ë²„ì „
# ëª¨ë¸: EfficientNetB0
# ê¸°ë²•: 2ë‹¨ê³„ íŒŒì¸íŠœë‹, ëª¨ë¸ ì „ìš© ì „ì²˜ë¦¬, Dropout, í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬, í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜

import os
import shutil
import zipfile
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.utils.class_weight import compute_class_weight

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# --------------------------------------
# 1. ë¡œì»¬ ì••ì¶• í•´ì œ ë° ë°ì´í„° ì¤€ë¹„
# --------------------------------------
def extract_if_needed(zip_path, extract_to):
    """ì§€ì •ëœ ê²½ë¡œì— í´ë”ê°€ ì—†ìœ¼ë©´ ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤."""
    if not os.path.exists(extract_to):
        print(f"ğŸ”„ ì••ì¶• í•´ì œ ì¤‘: {zip_path}")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(os.path.dirname(extract_to)) # ìƒìœ„ í´ë”ì— ì••ì¶• í•´ì œ
        print(f"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ: {extract_to}")
    else:
        print(f"âœ… í´ë” ì¡´ì¬: {extract_to} â†’ ì••ì¶• í•´ì œ ìƒëµ")

def classify_age(age):
    """ë‚˜ì´ë¥¼ 'child' ë˜ëŠ” 'adult'ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤. ì¤‘ê°„ ì—°ë ¹ëŒ€ëŠ” ì œì™¸í•©ë‹ˆë‹¤."""
    if age <= 14:
        return 'child'
    elif age >= 25:
        return 'adult'
    else:
        return None

def prepare_dataset():
    """ë°ì´í„°ì…‹ ì••ì¶•ì„ í’€ê³ , ì—°ë ¹ì— ë”°ë¼ ë¶„ë¥˜í•˜ì—¬ train/val/test í´ë”ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤."""
    print("--- ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹œì‘ ---")
    
    # ë¡œì»¬ í™˜ê²½ì— 'UTKFace.zip' íŒŒì¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    extract_if_needed("UTKFace.zip", "./UTKFace")

    # UTKFace ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
    utk_base_path = './UTKFace'
    # ì••ì¶• í•´ì œ ì‹œ 'UTKFace/UTKFace' êµ¬ì¡°ë¡œ í’€ë¦¬ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ ë‚´ë¶€ í´ë”ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
    utk_image_path = os.path.join(utk_base_path, 'UTKFace')
    if not os.path.exists(utk_image_path):
        utk_image_path = utk_base_path # ë‚´ë¶€ í´ë”ê°€ ì—†ìœ¼ë©´ ìƒìœ„ í´ë” ì‚¬ìš©

    merged_base = './merged_dataset_improved'
    if os.path.exists(merged_base):
        print(f"ì´ë¯¸ '{merged_base}' í´ë”ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ê¸°ì¡´ í´ë”ë¥¼ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.")
        shutil.rmtree(merged_base)
    
    subsets = ['train', 'val', 'test']
    for subset in subsets:
        for label in ['child', 'adult']:
            os.makedirs(os.path.join(merged_base, subset, label), exist_ok=True)

    all_files = []
    if os.path.exists(utk_image_path):
        print(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ê²½ë¡œ: {utk_image_path}")
        for f in os.listdir(utk_image_path):
            if f.lower().endswith(('.jpg', '.jpeg', '.png')) and '_' in f:
                try:
                    age = int(f.split('_')[0])
                    label = classify_age(age)
                    if label:
                        all_files.append((os.path.join(utk_image_path, f), label))
                except (ValueError, IndexError):
                    continue
    else:
        print(f"âš ï¸ UTKFace ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {utk_image_path}")

    if not all_files:
        print("ğŸš¨ ì²˜ë¦¬í•  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ ê²½ë¡œ ë° íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"ì´ {len(all_files)}ê°œì˜ ìœ íš¨ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    train, temp = train_test_split(all_files, test_size=0.3, stratify=[l for _, l in all_files], random_state=42)
    val, test = train_test_split(temp, test_size=0.5, stratify=[l for _, l in temp], random_state=42)

    def copy_data(file_list, subset):
        count = 0
        for src, label in file_list:
            if os.path.exists(src):
                filename = os.path.basename(src)
                dst = os.path.join(merged_base, subset, label, filename)
                shutil.copyfile(src, dst)
                count += 1
        print(f"'{subset}' ì„¸íŠ¸ì— {count}ê°œ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ.")

    copy_data(train, 'train')
    copy_data(val, 'val')
    copy_data(test, 'test')
    print("âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ë° ë³‘í•©/ë¶„ë¥˜ ì™„ë£Œ")

prepare_dataset()

# --------------------------------------
# 2. ë°ì´í„° ë¡œë”©
# --------------------------------------
base_dir = './merged_dataset_improved'
img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=20,
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.2,
    brightness_range=(0.7, 1.3),
    horizontal_flip=True,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_data = train_datagen.flow_from_directory(
    os.path.join(base_dir, 'train'),
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)
val_data = val_test_datagen.flow_from_directory(
    os.path.join(base_dir, 'val'),
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)
test_data = val_test_datagen.flow_from_directory(
    os.path.join(base_dir, 'test'),
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

# [ì˜¤ë¥˜ ìˆ˜ì •] í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì‹œ íƒ€ì…ì„ intë¡œ ëª…ì‹œ
weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_data.classes),
    y=train_data.classes.astype(int)  # <-- ì˜¤ë¥˜ ìˆ˜ì •ëœ ë¶€ë¶„
)
class_weight = dict(enumerate(weights))
print(f"ê³„ì‚°ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weight}")

# --------------------------------------
# 3. ëª¨ë¸ êµ¬ì„±
# --------------------------------------
base_model = EfficientNetB0(
    weights='imagenet',
    include_top=False,
    input_shape=(img_size[0], img_size[1], 3)
)

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
out = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=out)
model.summary()

# --------------------------------------
# 4. í•™ìŠµ
# --------------------------------------
early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1)
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1)

# --- 1ë‹¨ê³„: Feature Extraction ---
base_model.trainable = False
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
              loss='binary_crossentropy',
              metrics=['accuracy'])

print("\n--- 1ë‹¨ê³„ í•™ìŠµ ì‹œì‘ (Feature Extraction) ---")
history_phase1 = model.fit(train_data,
                           epochs=10,
                           validation_data=val_data,
                           class_weight=class_weight,
                           callbacks=[lr_scheduler])

# --- 2ë‹¨ê³„: Fine-tuning ---
base_model.trainable = True
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
              loss='binary_crossentropy',
              metrics=['accuracy'])

print("\n--- 2ë‹¨ê³„ í•™ìŠµ ì‹œì‘ (Fine-tuning) ---")
history_phase2 = model.fit(train_data,
                           epochs=50,
                           validation_data=val_data,
                           class_weight=class_weight,
                           callbacks=[early_stop, lr_scheduler],
                           initial_epoch=len(history_phase1.epoch))

# --------------------------------------
# 5. í‰ê°€ ë° ì €ì¥
# --------------------------------------
model.save('efficientnetb0_age_classifier_improved_fixed.h5')
print("\nâœ… ê°œì„ ëœ ëª¨ë¸ 'efficientnetb0_age_classifier_improved_fixed.h5' ì €ì¥ ì™„ë£Œ")

print("\n--- ìµœì¢… ëª¨ë¸ í‰ê°€ ---")
test_loss, test_acc = model.evaluate(test_data)
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì†ì‹¤ (Test Loss): {test_loss:.4f}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •í™•ë„ (Test Accuracy): {test_acc:.4f}")

y_true = test_data.classes
y_pred_probs = model.predict(test_data)
y_pred = (y_pred_probs > 0.5).astype(int).flatten()

cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_data.class_indices.keys())
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix (Improved Model - Fixed)")
plt.show()

print("\n--- Classification Report ---")
print(classification_report(y_true, y_pred, target_names=test_data.class_indices.keys())) 